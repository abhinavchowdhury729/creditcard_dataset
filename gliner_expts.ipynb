{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\miniconda3\\envs\\nlpEnv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\miniconda3\\envs\\nlpEnv\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GLiNER(\n",
       "  (token_rep_layer): TokenRepLayer(\n",
       "    (bert_layer): TransformerWordEmbeddings(\n",
       "      (model): DebertaV2Model(\n",
       "        (embeddings): DebertaV2Embeddings(\n",
       "          (word_embeddings): Embedding(128004, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "        (encoder): DebertaV2Encoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x DebertaV2Layer(\n",
       "              (attention): DebertaV2Attention(\n",
       "                (self): DisentangledSelfAttention(\n",
       "                  (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (pos_dropout): StableDropout()\n",
       "                  (dropout): StableDropout()\n",
       "                )\n",
       "                (output): DebertaV2SelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                  (dropout): StableDropout()\n",
       "                )\n",
       "              )\n",
       "              (intermediate): DebertaV2Intermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): DebertaV2Output(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                (dropout): StableDropout()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (rel_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (rnn): LstmSeq2SeqEncoder(\n",
       "    (lstm): LSTM(768, 384, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (span_rep_layer): SpanRepLayer(\n",
       "    (span_rep_layer): SpanMarkerV0(\n",
       "      (project_start): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.4, inplace=False)\n",
       "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (project_end): Sequential(\n",
       "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.4, inplace=False)\n",
       "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "      (out_project): Sequential(\n",
       "        (0): Linear(in_features=1536, out_features=3072, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.4, inplace=False)\n",
       "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prompt_rep_layer): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "    (1): Dropout(p=0.4, inplace=False)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GLiNER.from_pretrained(\"urchade/gliner_mediumv2.1\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_objects(text):\n",
    "    labels = [\"ORGANIZATION\"]\n",
    "    entities = model.predict_entities(text, labels, threshold=0.4)\n",
    "    my_dict = {}\n",
    "    # for ent in entities:\n",
    "    #     my_dict.setdefault(f\"spacy_default_{ent.label_}\", []).append(ent.text)\n",
    "\n",
    "    for ent in entities:\n",
    "        my_dict.setdefault(f\"spacy_gliner_{ent['label']}\", []).append(ent[\"text\"])\n",
    "    \n",
    "    return pd.Series(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>spacy_gliner_ORGANIZATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love my new Nike sneakers, they're so comfor...</td>\n",
       "      <td>[Nike]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McDonald's is my go-to place for a quick burge...</td>\n",
       "      <td>[McDonald's]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I need to buy some new Apple products, their l...</td>\n",
       "      <td>[Apple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coca-Cola is my favorite soft drink, nothing b...</td>\n",
       "      <td>[Coca-Cola]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I always buy my groceries from Walmart, they h...</td>\n",
       "      <td>[Walmart]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>I love the taste of Blue Bell frozen yogurt, i...</td>\n",
       "      <td>[Blue Bell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>I always buy my groceries from Safeway, they h...</td>\n",
       "      <td>[Safeway]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>I recently switched to using Gain laundry dete...</td>\n",
       "      <td>[Gain]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>I'm a loyal customer of Disney+, I love watchi...</td>\n",
       "      <td>[Disney+]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>I need to get a new pair of Brooks sneakers, t...</td>\n",
       "      <td>[Brooks]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentences  \\\n",
       "0   I love my new Nike sneakers, they're so comfor...   \n",
       "1   McDonald's is my go-to place for a quick burge...   \n",
       "2   I need to buy some new Apple products, their l...   \n",
       "3   Coca-Cola is my favorite soft drink, nothing b...   \n",
       "4   I always buy my groceries from Walmart, they h...   \n",
       "..                                                ...   \n",
       "95  I love the taste of Blue Bell frozen yogurt, i...   \n",
       "96  I always buy my groceries from Safeway, they h...   \n",
       "97  I recently switched to using Gain laundry dete...   \n",
       "98  I'm a loyal customer of Disney+, I love watchi...   \n",
       "99  I need to get a new pair of Brooks sneakers, t...   \n",
       "\n",
       "   spacy_gliner_ORGANIZATION  \n",
       "0                     [Nike]  \n",
       "1               [McDonald's]  \n",
       "2                    [Apple]  \n",
       "3                [Coca-Cola]  \n",
       "4                  [Walmart]  \n",
       "..                       ...  \n",
       "95               [Blue Bell]  \n",
       "96                 [Safeway]  \n",
       "97                    [Gain]  \n",
       "98                 [Disney+]  \n",
       "99                  [Brooks]  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"b1.csv\")\n",
    "df[\"Sentences\"] = df.Sentences.apply(lambda x:x.lstrip().replace(\";\", \",\"))\n",
    "df = pd.concat([df, df.Sentences.apply(get_objects)], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>spacy_gliner_ORGANIZATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>I always drink Red Bull when I need a pick-me-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>I love the new flavors of Lay's Stax chips, th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>I always drink Monster energy drinks when I ne...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>I love the new flavors of Lay's Poppables chip...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>I always use Ivory soap, it's gentle on my skin</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentences  \\\n",
       "45  I always drink Red Bull when I need a pick-me-...   \n",
       "55  I love the new flavors of Lay's Stax chips, th...   \n",
       "64  I always drink Monster energy drinks when I ne...   \n",
       "89  I love the new flavors of Lay's Poppables chip...   \n",
       "93    I always use Ivory soap, it's gentle on my skin   \n",
       "\n",
       "   spacy_gliner_ORGANIZATION  \n",
       "45                       NaN  \n",
       "55                       NaN  \n",
       "64                       NaN  \n",
       "89                       NaN  \n",
       "93                       NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.spacy_gliner_ORGANIZATION.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
