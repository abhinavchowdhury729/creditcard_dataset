{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhin\\miniconda3\\envs\\nlpEnv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-31 18:49:17,601 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "tagger = SequenceTagger.load('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_objects(text):\n",
    "    my_dict = {}\n",
    "    sentence = Sentence(text)\n",
    "    tagger.predict(sentence)\n",
    "    for ent in sentence.get_spans('ner'):\n",
    "        my_dict.setdefault(f\"flair_{ent['label']}\", []).append(ent[\"text\"])\n",
    "    \n",
    "    return pd.Series(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mb2.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mSentences\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mSentences\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x:x\u001b[39m.\u001b[39mlstrip()\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df, df\u001b[39m.\u001b[39;49mSentences\u001b[39m.\u001b[39;49mapply(get_objects)], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m df\n",
      "File \u001b[1;32mc:\\Users\\abhin\\miniconda3\\envs\\nlpEnv\\lib\\site-packages\\pandas\\core\\series.py:4908\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4780\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4781\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4787\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4788\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4789\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4790\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4791\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4906\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4907\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4908\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4909\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   4910\u001b[0m         func,\n\u001b[0;32m   4911\u001b[0m         convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype,\n\u001b[0;32m   4912\u001b[0m         by_row\u001b[39m=\u001b[39;49mby_row,\n\u001b[0;32m   4913\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   4914\u001b[0m         kwargs\u001b[39m=\u001b[39;49mkwargs,\n\u001b[0;32m   4915\u001b[0m     )\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\abhin\\miniconda3\\envs\\nlpEnv\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[39m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\abhin\\miniconda3\\envs\\nlpEnv\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[39m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[39m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[39m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[39m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[39m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mdtype, CategoricalDtype) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[39m=\u001b[39;49mcurried, na_action\u001b[39m=\u001b[39;49maction, convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\abhin\\miniconda3\\envs\\nlpEnv\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mmap(mapper, na_action\u001b[39m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[39mreturn\u001b[39;00m algorithms\u001b[39m.\u001b[39;49mmap_array(arr, mapper, na_action\u001b[39m=\u001b[39;49mna_action, convert\u001b[39m=\u001b[39;49mconvert)\n",
      "File \u001b[1;32mc:\\Users\\abhin\\miniconda3\\envs\\nlpEnv\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m na_action \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmap_infer(values, mapper, convert\u001b[39m=\u001b[39;49mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[39m=\u001b[39misna(values)\u001b[39m.\u001b[39mview(np\u001b[39m.\u001b[39muint8), convert\u001b[39m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m, in \u001b[0;36mget_objects\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      4\u001b[0m tagger\u001b[39m.\u001b[39mpredict(sentence)\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m ent \u001b[39min\u001b[39;00m sentence\u001b[39m.\u001b[39mget_spans(\u001b[39m'\u001b[39m\u001b[39mner\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     my_dict\u001b[39m.\u001b[39msetdefault(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mflair_\u001b[39m\u001b[39m{\u001b[39;00ment[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, [])\u001b[39m.\u001b[39mappend(ent[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      8\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mSeries(my_dict)\n",
      "File \u001b[1;32mc:\\Users\\abhin\\miniconda3\\envs\\nlpEnv\\lib\\site-packages\\flair\\data.py:613\u001b[0m, in \u001b[0;36mSpan.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Token:\n\u001b[1;32m--> 613\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokens[idx]\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"b2.csv\")\n",
    "df[\"Sentences\"] = df.Sentences.apply(lambda x:x.lstrip().replace(\";\", \",\"))\n",
    "df = pd.concat([df, df.Sentences.apply(get_objects)], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span[11:12]: \"Flipkart\" → LOC (0.3284)\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence(df.Sentences[0])\n",
    "tagger.predict(sentence)\n",
    "my_dict = {}\n",
    "for ent in sentence.get_spans('ner'):\n",
    "    print(ent)\n",
    "    # my_dict.setdefault(f\"flair_{ent['label']}\", []).append(ent[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Flipkart',\n",
       "  'start_pos': 53,\n",
       "  'end_pos': 61,\n",
       "  'labels': [{'value': 'LOC', 'confidence': 0.3283701539039612}]}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.to_dict(tag_type='ner')[\"entities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
